import fs from 'fs';
import path from 'path';
import fetch from 'node-fetch';
import matter from 'gray-matter';

function getGithubToken() {
    return process.env.GITHUB_TOKEN || process.env.GH_TOKEN || process.env.GITHUB_PAT || process.env.PERSONAL_TOKEN;
}

const projectsPath = path.join(process.cwd(), 'src', 'data', 'projects.json');
const openSourcePath = path.join(process.cwd(), 'src', 'data', 'github-projects.json');
const configPath = path.join(process.cwd(), 'config', 'github.json');

const projects = JSON.parse(fs.readFileSync(projectsPath, 'utf8'));
const openSourceProjects = fs.existsSync(openSourcePath) ? JSON.parse(fs.readFileSync(openSourcePath, 'utf8')) : [];
const config = fs.existsSync(configPath) ? JSON.parse(fs.readFileSync(configPath, 'utf8')) : { excludeFromPages: [] };

async function fetchRepo(repo) {
    try {
        const token = getGithubToken();
        const headers = { Accept: 'application/vnd.github.v3+json' };
        if (token) headers.Authorization = `token ${token}`;
        const res = await fetch(`https://api.github.com/repos/${repo}`, { headers });
        if (!res.ok) return {};
        const j = await res.json();
        return { stars: typeof j.stargazers_count === 'number' ? j.stargazers_count : undefined, forks: typeof j.forks_count === 'number' ? j.forks_count : undefined };
    } catch {
        return {};
    }
}

async function fetchReadme(repo) {
    try {
        const token = getGithubToken();
        const headers = { Accept: 'application/vnd.github.v3+json' };
        if (token) headers.Authorization = `token ${token}`;
        const res = await fetch(`https://api.github.com/repos/${repo}/readme`, { headers });
        if (!res.ok) return null;
        const j = await res.json();
        return Buffer.from(j.content, 'base64').toString('utf8');
    } catch {
        return null;
    }
}

(async () => {
    console.log('Generating GitHub project pages (simple script)');
    const projectsDir = path.join(process.cwd(), 'content', 'projects');
    if (!fs.existsSync(projectsDir)) fs.mkdirSync(projectsDir, { recursive: true });

    // Files to always ignore (do not generate). These are target markdown filenames
    // that will be skipped and removed if they already exist.
    const IGNORE_FILE_NAMES = [
        'Ethics-AI-Data.md',
        'Guerra-Mundial-POA-2020-Simulator.md',
        'Matematica-ONGEP.md',
        'rossetti-audio.md'
    ];

    // Remove any existing ignored files so they won't remain in the content folder.
    for (const fn of IGNORE_FILE_NAMES) {
        const p = path.join(projectsDir, fn);
        if (fs.existsSync(p)) {
            try {
                fs.unlinkSync(p);
                console.log('Deleted ignored file:', p);
            } catch (err) {
                console.warn('Failed to delete ignored file:', p, err && err.message);
            }
        }
    }

    // Combine both project lists, ensuring no duplicates by repo
    const allProjects = [...projects];

    // Add open source projects that aren't already in the main projects list
    for (const osProject of openSourceProjects) {
        const osRepo = osProject.repo || (osProject.link && osProject.link.includes('github.com') ?
            new URL(osProject.link).pathname.split('/').filter(Boolean).slice(0, 2).join('/') : null);
        if (!osRepo) continue;

        // Check if this repo is already in the main projects list
        const exists = allProjects.some(p => {
            const pRepo = p.repo || (p.link && p.link.includes('github.com') ?
                new URL(p.link).pathname.split('/').filter(Boolean).slice(0, 2).join('/') : null);
            return pRepo === osRepo;
        });

        if (!exists) {
            allProjects.push({
                title: osProject.name || osRepo.split('/')[1],
                link: osProject.link || `https://github.com/${osRepo}`,
                desc: osProject.description,
                tags: osProject.topics || [],
                repo: osRepo
            });
        }
    }

    for (const p of allProjects) {
        const repo = p.repo || (p.link && p.link.includes('github.com') ? new URL(p.link).pathname.split('/').filter(Boolean).slice(0, 2).join('/') : null);
        if (!repo) continue;
        if (config.excludeFromPages.includes(repo)) continue;

        const [stats, readme] = await Promise.all([fetchRepo(repo), fetchReadme(repo)]);
        const frontmatter = {
            title: p.title,
            date: undefined,
            tags: p.tags,
            excerpt: p.desc,
            // Try to extract a cover image from the README (first markdown or HTML <img>)
            cover: undefined,
            original_path: p.link,
            stars: stats.stars,
            forks: stats.forks,
            repo
            // Mark auto-generated files so users can opt-out by setting autogenerated: false
            , autogenerated: true
        };
        // Remove undefined values because YAML dump fails on `undefined`
        Object.keys(frontmatter).forEach((k) => {
            if (frontmatter[k] === undefined) delete frontmatter[k];
        });
        // If we fetched a README, try to find the first image-like URL to use as cover.
        if (readme) {
            // Collect all markdown image candidates: ![alt](url)
            const mdImgRe = /!\[[^\]]*\]\(([^)\s]+)(?:\s+"[^"]*")?\)/gi;
            // Collect all HTML image candidates: <img src="..."> or <img src='...'>
            const htmlImgRe = /<img[^>]+src=["']([^"']+)["'][^>]*>/gi;

            const mdImgs = Array.from(readme.matchAll(mdImgRe)).map((m) => m[1]);
            const htmlImgs = Array.from(readme.matchAll(htmlImgRe)).map((m) => m[1]);
            const candidates = [...mdImgs, ...htmlImgs];

            const isLikelyImage = (u) => {
                if (!u) return false;
                const lower = u.split('?')[0].toLowerCase();
                // Common image file extensions
                if (/(\.png|\.jpe?g|\.gif|\.svg|\.webp|\.bmp)(#.*)?$/i.test(lower)) return true;
                // Known raw/image hosts or direct raw paths
                if (/raw\.githubusercontent\.com|raw\.github|githubusercontent\.com|cdn\.|imgur\.com|unsplash\.com|images\.unsplash\.com/i.test(u)) return true;
                return false;
            };

            let chosen = null;
            for (let c of candidates) {
                if (!c) continue;
                let img = c.trim();

                // Normalize relative paths (convert to raw.githubusercontent link)
                if (!/^https?:\/\//i.test(img) && !img.startsWith('/')) {
                    img = img.replace(/^\.\.?\//, '');
                    img = `https://raw.githubusercontent.com/${repo}/main/${img}`;
                } else {
                    // Convert GitHub blob URLs to raw URLs when possible
                    const githubBlob = img.match(/https?:\/\/github\.com\/([^/]+\/[^/]+)\/blob\/([^#?]+)(?:[?#].*)?$/i);
                    if (githubBlob) {
                        img = `https://raw.githubusercontent.com/${githubBlob[1]}/${githubBlob[2]}`;
                    }
                }

                if (isLikelyImage(img)) {
                    chosen = img;
                    break;
                }
            }

            if (chosen) {
                // Store cover URL directly and ensure it doesn't get block scalar indicators by forcing quotes
                frontmatter.cover = chosen.toString();
            }
        }

        // Configure gray-matter to avoid block scalar indicators. Do NOT force quotes
        // so that plain URLs (e.g. https://...) are written without surrounding quotes.
        const content = matter.stringify(readme || `# ${p.title}\n\nNo README available.`, frontmatter, {
            flowLevel: 1 // Keep simple inline flow where appropriate
        });
        // Post-process content to avoid unnecessary quoting for plain URLs in the `cover` field.
        // Some YAML dumpers may decide to quote strings that look like URLs; remove those quotes
        // for a cleaner frontmatter like: cover: https://raw.githubusercontent.com/...
        let processedContent = content.replace(/^(cover:\s*)['"]([^'"]+)['"]/m, '$1$2');

        const fileName = `${repo.split('/')[1]}.md`;
        // Skip files that are explicitly ignored
        if (IGNORE_FILE_NAMES.includes(fileName)) {
            console.log('Skipping generation (ignored):', fileName);
            continue;
        }
        const filePath = path.join(projectsDir, fileName);
        let shouldWrite = true;
        if (fs.existsSync(filePath)) {
            const existing = fs.readFileSync(filePath, 'utf8');
            try {
                const parsed = matter(existing);
                if (parsed?.data && parsed.data.autogenerated === false) {
                    console.log('Skipping (user-edited):', filePath);
                    continue;
                }
            } catch (err) {
                // parsing failed; fall back to normal behaviour
            }
            // Compare against processedContent (quotes removed) so minor formatting
            // differences like quoted vs unquoted URLs trigger a write.
            shouldWrite = existing !== processedContent;
        }
        if (shouldWrite) {
            fs.writeFileSync(filePath, processedContent);
            console.log('Wrote', filePath);
        } else {
            console.log('Unchanged', filePath);
        }
    }

    console.log('Done');
})();
